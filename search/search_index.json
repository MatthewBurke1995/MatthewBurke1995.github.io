{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Matt's thoughts on things","text":"<p>\ud83d\udc4b Hi! Thanks for checking out this page.</p> <p>I'm Matt and I've worked as a Software Engineer and Data Scientist. I graduated with a BSc in Physics, but discovered I was more interested in software during my studies. In my spare time I like to read non-fiction, go hiking, be disappointed by Tottenham and watch every movie that has ever recieved an oscar nomination.</p> <p>I have used R, Python, Javascript/Node, Java and C# in professional contexts while working at the Reserve Bank of Australia (Data Analyst in a central bank), IBM (Software Engineer in search and web development domains) and Wavebridge (Quantative Researcher in a hedge fund). In terms of human languages I am fluent in Korean. </p> <p>You can see my \"Resume here!\"</p>"},{"location":"blog/","title":"Blog","text":"<p>This is my blog, I write mostly for myself about things I find interesting such as programming, mathematics and what I have been reading recently.</p>"},{"location":"blog/2023/01/28/abc-radio/","title":"ABC Radio","text":"<p>I wrote a python library for searching and parsing through the historical catalgoue of songs played on ABC (Australian Broadcasting Corporation) radio channels. This is especially timely since TripleJ will be releasing it's \"Hottest 100\" playlist for 2022 in a few days. </p> <p>I'm particularly interested in the TripleJ data due to it aligning with my music preferences. TripleJ tends to have a good mix of quality and breadth in its music selection and is arguably the reason that the Australian music industry as a whole has punched above its weight for so long. Which is why I'll be looking at the TripleJ data in particular.</p> <p>Let's calculate which song and which artist had the most airtime throughout 2022. </p>"},{"location":"blog/2023/01/28/abc-radio/#usage","title":"Usage","text":"install abc-radio-wrapper pypi package<pre><code>pip install abc-radio-wrapper\n</code></pre> <pre><code>import pandas as pd\nimport abc_radio_wrapper\nABC = abc_radio_wrapper.ABCRadio()\nstartDate: datetime = datetime.fromisoformat(\"2022-01-01T00:00:00+00:00\")\nendDate: datetime = datetime.fromisoformat(\"2022-12-31T23:59:59+00:00\")\nradio_play_list = []\n#search through 1 year period of triplej songs, set limit to 100 for faster results (default is 10)\nfor search_result in ABC.continuous_search(from_=startDate, to=endDate, station=\"triplej\", limit=100):\nprint(search_result.offset/search_result.total)\nfor radio_play in search_result.radio_songs:        \nartists = [artist.name for artist in radio_play.song.artists]\nif len(artists) ==0: continue\nradio_play_list.append({\"song\":radio_play.song.title, \"time\":radio_play.played_time, \"artist\":artists[0]})\ndf = pd.DataFrame(radio_play_list)\n#get the top 20 artists by playtime\nprint(\ndf.groupby('artist').count().sort_values('time', ascending=False)[0:20]\n)\nsong  time  artists\nartist                                      \nArt Vs Science            876   876      876\nSpacey Jane               649   649      649\nThe Wombats               562   562      562\nBall Park Music           519   519      519\nVance Joy                 508   508      508\nFlume                     485   485      485\nOcean Alley               468   468      468\nbeabadoobee               453   453      453\nWet Leg                   437   437      437\nMaggie Rogers             431   431      431\nG Flip                    426   426      426\nCharli XCX                421   421      421\nKendrick Lamar            412   412      412\nEliza &amp; The Delusionals   409   409      409\nFoals                     407   407      407\nSycco                     406   406      406\nBeddy Rays                395   395      395\nmerci, mercy              394   394      394\nLil Nas X                 389   389      389\nMura Masa                 382   382      382\n</code></pre> <p>So what could you use this data for? From here if you were to pick a particular time interval you could imagine integrating with the youtube or spotify API to create a playlist for a certain day or month. I think a similar method is already used to compile the hottest 100 playlists on youtube after each January, at least I'd hope people weren't adding each item by hand. You could also challenge my assumption that TripleJ has a wide variety of music. One method would be to calculate the Gini Impurity of the song catalouge where each artist is it's own category. You'd need to compare the results with other radio stations or other periods of time. </p> <p>And a convenience function for matching a song to a youtube video.</p> generate a youtube video from a song title<pre><code>import requests\nimport urllib.parse\ndef get_youtube_url(song_name: str, apikey: str) -&gt; str:\nr= requests.get(\"https://youtube.googleapis.com/youtube/v3/search?q=\"+urllib.parse.quote_plus(song_name)+\"&amp;key=\"+apikey)\nvideo_id = r.json()['items'][0]['id']['videoId']\nreturn \"https://www.youtube.com/watch?v=\"+video_id\n</code></pre>"},{"location":"blog/2023/01/16/the-golden-rule-of-time/","title":"The Golden Rule of Time","text":"<p>Why do some people in safe jobs work long nights with no chance of reward? Why do we espouse certain values that we don't follow?</p> <p>Recently, I read \"The Time Paradox\" by Zimbardo and Boyd. I enjoy reading pop psychology as long as they have a bit more depth and legitimacy than power posing, fortunately Boyd and Zimbardo's writing about the psychology of time is profound. Although it is not the focus of the book, the section I enjoyed the most was their discussion of \"The Golden Rule of Time\".</p> <p>The golden rule of time goes something like this: \"Spend your time the way you wish others would spend their time.\" A reference point might be more useful, imagine your son or daughter has to make the choice of working until late  at a job with no prospect of promotion in the immediate future or they can go home on time? Almost everyone would wish that their child enjoyed their freetime yet that is not the choice that many people make in reality. The golden rule of time is a way of framing the strangeness of these choices and clarifying the decision making process.</p> <p>As to the questions in the first paragraph, I have no good answer. Maybe it is due to Freud's hypothesized fear of death, which exists on such a subconscious level that we don't consider it when speaking of others. Maybe we are at our most rational when we consider other people. With 'The Golden Rule of Time' in your toolbelt I hope that you can use that rationality, usually reserved for others, on yourself.</p> <p>The Time Paradox: The New Psychology of Time That Will Change Your Life</p>"},{"location":"blog/2023/01/01/gradio/","title":"Gradio","text":"<p>I've been taking Jeremy Howard's \"Practical Deep Learning for Coders\". The course is practical so it's no surprise that it discusses deployment during Lesson Two and in the process introduces the <code>gradio</code> package. </p> <p>Gradio makes a good use case for demonstrating deep learning models. The skill sets for starting up a webserver, creating a deep learning model and writing javascript for the presentation layer are different and having to do them all at once can be frustrating. Gradio takes care of the webserver and frontend part of the sandwich so you can focus on the meatier functionality bits.</p> <p>It's a good use case but there is still the issue of deploying the gradio application to the internet on a machine that can handle deep learning workloads. Thankfully last year Hugging Face added \"Hugging Face Spaces\" to their suite of tools. Each space has a limit of 16GB RAM and 8 CPU cores and hosts a docker container exposed to the internet.</p> <p>Last year I published a Korean language sentiment analysis pipeline to Hugging Faces, so I'll be using that as the basis for the gradio deployment.</p> <p>You can find the language model here. And the repository for the gradio application here. Since it's hosted on a site which allows CORS I can call to it from this frontend without any issues. One last thing about the model is that it's trained on movie review data, if you give it the phrase \"\ub208\ubb3c \ub0ac\ub2e4\" (\"I shed a tear\") it will predict it as having a positive sentiment with a &gt;95% confidence rating.</p> <p> </p>"},{"location":"blog/2023/03/05/punished-by-rewards/","title":"Punished by Rewards","text":"<p>I've been reading \"Punished by Rewards\" by Alfie Kohn, which is a book about the limits of behaviourism and incentive systems that assume behaviourism as the one and only paradigm of explanining human behaviour. There was a point in the mid 1900's where the field of psychology was captured by behaviourism and the fact that it remains the predominant way of explanining human behaviour amongst the suits is unfortunate. Below I've written my thoughts on the topic as I read through the book.</p>"},{"location":"blog/2023/03/05/punished-by-rewards/#current-reward-systems-are-not-meritocratic","title":"Current reward systems are not meritocratic","text":"<p>Modern incentive systems are unreasonably top weighted. One of the strangest aspects of modern publically traded companies is executive pay. Why should the highest paid employee's (I'm including CEO's as employees since their work agreements are dictated by the board) be the most highly incentivized to do the work? Is there not am implication that they could not be trusted to work effectively without these incentives? What can be most puzzling is how these incentives are aligned with results. If the share price goes up then investors will be happy, but how much of this happiness should be attributed to the CEO is debatable. What's more if this type of incentive system was so effective then eventually companies that didn't partake in these incentive systems would soon be outcompeted. Since we live in a world where there are many companies that treat their employees well and don't resort to explicit KPI's then this is not the case.</p>"},{"location":"blog/2023/03/05/punished-by-rewards/#extrinsic-vs-intrinsic-motivation","title":"Extrinsic vs Intrinsic motivation","text":"<p>Extrinsic motivation is the antithesis of intrinsic motivation. A recurring example throughout Kohn's book is the Pizza Hut program to reward young students with pizza coupons once they read a predetermined number of books. There are some strange implications to this program, if pizza is the incentive then we are implying that reading needs to be incentivized. When we rely on extrinsic motivation we weaken the implicit value of a task. Even if we are selling our labour it is best to not make the relationship explicit. The best performing workers are those that find enjoyment, challenge and learning opportunities in their work.</p>"},{"location":"blog/2023/03/05/punished-by-rewards/#reward-systems-are-a-way-of-exerting-control","title":"Reward systems are a way of exerting control","text":"<p>In the early 2000's the South Korean President, Kim Dae-Joong, instituted what is known as the \"Sunshine Policy\" towards North Korea as a way to exert control. When North Korea makes nuclear weapons there is no way for South Korea to punish them, but under the \"Sunshine Policy\" they have the option to remove rewards. With the Sunshine Policy agreement North Korea would receive aid from the South under the condition that they would stop producing missiles. One side has nuclear weapons but who is in control? Much of modern managerial theory is built on the premise that employees economic output must be controlled. Methods of control often have the opposite effect of their intentions, they can lead to a breakdown of trust and a less efficient working environment. In the example of children reading books to receive pizza, if a child were to come to you and say they read 50 books over the last year are you likely to believe them? </p>"},{"location":"blog/2023/03/05/punished-by-rewards/#punishment-is-not-the-opposite-of-reward","title":"Punishment is not the opposite of reward","text":"<p>Punisment is not the opposite of reward, they are one and the same. Take the previous example of the \"Sunshine Policy\", withdrawing rewards was the equivelant of a punishment, conversely giving a reward is the opposite of punishment. There are many cases where peple are morally opposed to punishments but are supportive of rewards, This is morally inconsistent, if you are in favour of one then you should also be in favour of the other.</p> <p>For anyone that is still reading, I would recommend the book \"Punished by Rewards\" for all current and future parents, teachers and managers. Not relying on behaviourist methods is challenging but effective. The opposite is lazy and counterproductive. If you read the book you will find not just issues but solutions</p>"},{"location":"blog/2023/01/17/the-friendship-paradox/","title":"The Friendship Paradox","text":"<p>On average your friends will have more friends than you. On average the football team you support will be one of the mosty popular football teams in the world. And the train or bus you took to work today was close to full capacity.</p> <p>In graph theory there is a concept called \"The Friendship Paradox\" which stated plainly goes something like this \"your friends have more friends than you\". If we were to measure this, the recipe would look like:</p>"},{"location":"blog/2023/01/17/the-friendship-paradox/#procedure","title":"Procedure","text":"<ol> <li>Sample a random node (or ask a random person)</li> <li>Count the number of edges (i.e. 'degree') for that node (how many friends can you count)</li> <li>Calculate the degree for each neighbouring node (number of friends your friends have)</li> <li>Take the average of the neighbouring nodes degrees </li> <li>Assert that the average degree of neighbouring nodes is higher than the degree of the randomly sampled node.</li> </ol> <p>But it's also true that you or any other random node in the friendship graph could have more friends than the average node. The paradox occurs due to the difference in sampling methods.</p> <p>Let's take the example of passengers catching a bus to see how this happens. Imagine there are only two busses in the world. One that takes 50 passengers and the other that takes 5 passengers.</p> <p>If we ask each busdriver how many passengers they have we get an array of [50,5] for which the average is 27.5, a reasonable amount. But if we were to ask each passenger how many passengers are on the bus we get an array of [50, ..x48, 50, 5, 5, 5, 5, 5] with an average of:</p> \\[     mean(degree) = (50 * 50 + 5 * 5)/(50+5) ~= 45.9... \\] <p>We have two 'averages' for the same metric with vastly different results depending on if we sample each node or each edge (or which type of node in the case of a bipartite graph). Using \\(k\\) to represent the degrees of a node we can express the two alternatives as:</p>"},{"location":"blog/2023/01/17/the-friendship-paradox/#per-node-average","title":"Per node average","text":"\\[     \\sum_{i=0}^n \\frac{k_i}{n} = &lt;k&gt; \\]"},{"location":"blog/2023/01/17/the-friendship-paradox/#per-degree-average","title":"Per degree average","text":"\\[     \\frac{&lt;k^2&gt;}{&lt;k&gt;} \\]"},{"location":"blog/2023/01/17/the-friendship-paradox/#what-should-you-measure","title":"What should you measure?","text":"<p>Which metric is more useful depends on the circumstances. If you are a busdriver then you will be assigned randomly to take on a bus route in which case the best estimate for the number of passengers at any one time is \\(&lt;k&gt;\\) but if you are a passenger then you are more likely to catch the bus during peek times for the same reason as everyone else, in which case the per degree average is a better estimate of how busy the bus will be. </p> <p>The same metaphor can works teachers and students in classrooms. And when we don't have a bipartite graph we end up with the friendship paradox.</p>"},{"location":"blog/2023/06/05/the-software-architect-elevator-redefining-the-architects-role-in-the-digital-enterprise-by-gregor-hohpe/","title":"The Software Architect Elevator: Redefining the Architect's Role in the Digital Enterprise By Gregor Hohpe","text":"<p>I recenently read Hohpe's book on the role, objetives and skills of a software architect. This book is dense with information but I was able to read it at a breezy pace, Hohpe walks the walk when he writes than an architect has to be succinct and insightful. </p> <p>The book is divided into five equal length sections i.e. 'Architects', 'Architecture', 'Communication', 'Organizations' and 'Transformation'.</p>"},{"location":"blog/2023/06/05/the-software-architect-elevator-redefining-the-architects-role-in-the-digital-enterprise-by-gregor-hohpe/#architects","title":"Architects","text":"<p>The title of the book comes from the first chapter, architects are able to ride the elevator between the top floor executive suite and the engine room of IT, bypassing the levels of middle management. To be effective they must be skillful, impactful and have leadership qualities. If they do everything right and reach the penthouse they must not stay there, in case their skills become blunt or they lose context of the engine room.</p>"},{"location":"blog/2023/06/05/the-software-architect-elevator-redefining-the-architects-role-in-the-digital-enterprise-by-gregor-hohpe/#architecture","title":"Architecture","text":"<p>Architecture is about keeping your options open. In the financial world you can buy put or call options to sell or buy a stock at a certain price by a future date, in which case you delay the choice of buying or selling. This is valuable in the same way that delaying software choices before you have a full picture is valuable. </p> <p>In software it's important to cut the dead weight, if you never retire a software system you will end up living among zombies. The lifecycle of creating, upgrading and removing systems is much easier if they are software defined.</p>"},{"location":"blog/2023/06/05/the-software-architect-elevator-redefining-the-architects-role-in-the-digital-enterprise-by-gregor-hohpe/#communication","title":"Communication","text":"<p>Communicating is a lot like mountain climbing. Imagine you have to take someone up to the top of a hill so they can see what you have seen. If you take the steepest path then you, the guide, will reach your destination quickly but many will not be able to follow. But if you take the gradual path then everyone will be able to reach the peak of enlightenment. To help in this effort, it's good to build a shared vocabulary (similar to ubiquitous language in DDD), and keep to the same level of abstraction within a document e.g. don't talk about hardware, software and the network within the same paragraph.</p>"},{"location":"blog/2023/06/05/the-software-architect-elevator-redefining-the-architects-role-in-the-digital-enterprise-by-gregor-hohpe/#organizations","title":"Organizations","text":"<p>Stephen Bungay talks about the three gaps of control and the 'control illusion'. An organization creates plans based on what they perceive reality to be, those plans turn into actions which in turn should affect reality. Each side of this triangle (reality, plans, actions) represents a gap that the organization seeks to fill. If the plans are not being built on reality there is a knowledge gap, if plans do not lead to actions then there is an alignment gap (solution: micromanaging) and if actions don't work there is an effects gap. The 'control illusion' is the idea that these gaps can be filled in a top down way. The only real control is autonomy which requires trusting the team, strategy, enablement and continuous feedback.</p> <p>Copying the processes of other hip technology companies is cargoculting. </p>"},{"location":"blog/2023/06/05/the-software-architect-elevator-redefining-the-architects-role-in-the-digital-enterprise-by-gregor-hohpe/#transformation","title":"Transformation","text":"<p>Similar to the twelve steps of Alchoholics Anonymous the first step of transformation is to admit that there is a problem, sometimes the most effective thing an architect can do is to show where the pain is. </p>"},{"location":"blog/2023/01/16/unix-named-pipes/","title":"Unix Named Pipes","text":""},{"location":"blog/2023/01/16/unix-named-pipes/#message-queues","title":"Message Queues","text":"<p>Message queues are an architectural pattern to decouple the process of gathering tasks and resolving tasks. There are a couple of reasons why you would use this design pattern. It might not be possible to complete the task within a single request reply loop or it might be easier to resolve tasks in a batch method due to large initial process startup costs.</p> <p>Assuming that the process that resolves the work is different to the one that gathers the work (i.e. is a message queue and not a task queue) then this is also a form of interprocess communication. Other options for interprocess communication could be JSON over HTTP (for processes across servers), shared memory such as Redis or the filesystem for processes that run on the same server.</p>"},{"location":"blog/2023/01/16/unix-named-pipes/#unix-pipes","title":"Unix Pipes","text":"<p>In unix everything is a file, including pipes. As a brief review pipes are a way of turning stdin (read as \"standard input\") to stdout (\"standard output\"). The following script uses <code>cat</code> which takes a file or several files from stdin and prints to stdout. The pipe in the middle takes that stdout and converts it to stdin for the next process which is also cat and prints the text to stdout. 'cat' converts stdin to stdout and the pipe converts stdout to stdin, together they act like the identity function for any text. The following two commands do the same thing.</p> <pre><code>cat book.txt        cat book.txt | cat  </code></pre> <p>\ud83d\ude2e\u200d\ud83d\udca8 that was a lot to parse out. Pipes are powerful and efficient when each process can handle the data as a stream. We can compare the time taken to run a pipe of 20 cats versus the time taken to run a pipe of one cat.</p> <pre><code>time cat book.txt                       #...  0.007 total\ntime cat book.txt | cat | \ud83d\udc31x20 | cat   #...  0.021 total\n</code></pre> <p>More processes means more processing but there is a lot of time saved when you dont have to read from the file system each time. We could also create a strange pipe by using cat if we save the stdout to an intermediate file and then read that file as the stdin for the next process, this takes roughly twice the time and also twice the cpu power as the unix pipe version.</p> <pre><code>cat book.txt &gt; tempfile; cat tempfile &gt; tempfile ; cat tempfile &gt; tempfile;...\n</code></pre> <p>Writing to files is always an option, there is a huge overlap between pipes and files in terms of functionality. But one reason why files aren't appropriate is when we want to make sure that each line is processed exactly once even if several processes are accessing the content.</p>"},{"location":"blog/2023/01/16/unix-named-pipes/#unix-named-pipes-as-a-message-queue","title":"Unix Named Pipes as a Message Queue","text":"<p>Unix has a feature called 'Named Pipes' where we can give a pipe a name, let it persist in the file system. Unlike regular pipes named pipes can persist over time, and unlike regular files they have the guarantee that each line will only be processed once.</p> named pipes in bash<pre><code>mkfifo newnamedpipe\necho \"hi\" &gt; newnamedpipe\n\n#open up new terminal\ncat newnamedpipe #output of \"hi\"\ncat newnamedpipe #no output, waiting for new message to join queue.\n</code></pre> Read and write to named pipes in Python<pre><code>import os\nPIPE_NAME = \"my_named_pipe\"\ndef write_named_pipe(pipe_name,message):\n# Create the named pipe if it does not exist\nif not os.path.exists(pipe_name):\nos.mkfifo(pipe_name)\n# Open the named pipe\nwith open(pipe_name, \"w\") as pipe:\n# Write the message to the pipe\npipe.write(\"Hello, other process!\")\npipe.flush()\ndef read_named_pipe(pipe_name):\n# Open the named pipe for reading\nwith open(pipe_name, \"r\") as pipe:\nresponse = pipe.read()\nprint(response)\n</code></pre>"},{"location":"blog/2023/01/16/unix-named-pipes/#wrap-up","title":"Wrap up","text":"<p>You can use named pipes as a simple message queue on any unix distribution.</p>"},{"location":"blog/2023/05/28/bicycle-tour-halfway-across-the-country-seoul-daegu/","title":"Bicycle Tour - halfway across the country (Seoul - Daegu)","text":"<p>In every man's life, there comes a time when he must hang up his skateboard and put on his bicycle lycra. For me, this happened soon after I heard that there was a bicycle path that follows the Han River and makes a diagonal cut across the country. The path starts in the northwest corner and ends in the southeast city of Busan, after traveling 600 kilometers alongside the Han River, the Seojae mountain pass, and the Nakdong River. I would start in the eastern end of Seoul and finish in Daegu, exactly half of the full route and literally \"halfway across the country.\"</p> <p>Quote</p> <p>\u201cYou're off to Great Places! Today is your day! Your mountain is waiting, So... get on your way!\u201d  - Dr Seuss</p>"},{"location":"blog/2023/05/28/bicycle-tour-halfway-across-the-country-seoul-daegu/#preparation","title":"Preparation","text":"<p>I first heard about the Four Rivers bike path while scrolling through the Korean section on Reddit. There was a post that contained around 20 images, some of them close-ups of a road bike with a backpack attached, while others showcased lush Korean fields with distant mountains in the background. The title was something like \"I rode the Four Rivers bike track, and it was the best thing I did in Korea.\" This sparked dozens of comments such as, \"How did you prepare?\" - \"I did this route in March 2018...\" - \"What's the best time to go?\"</p> <p>I took little notice the first time I saw it, but occasionally the topic would come up again, and each time I felt a twinge of jealousy towards those who had the time, resources, and physical conditioning to embark on a cycling journey through South Korea.</p> <p>After spending two years in and out of lockdown in Canberra, I made the decision to visit my partner in Korea. Due to the Australian travel ban, I could only justify my trip by applying for a 6+ month Visa. Therefore, I decided to enroll in a 6-month Korean language course. To make an informed choice, I created a grid with each university plotted based on the number of classroom hours on the x-axis and the cost on the y-axis. While most people would opt for the bottom-right option (i.e. value-for-money), I wanted to maximize both my time and money spent with my partner (i.e. minimize teaching hours). So I ended up at the prestigous Seoul National University where I would attend morning classes four times a week. </p> <p>With the not-likely-to-be-repeated abundance of free time I had loose plans to start in April 2022 but due to finding work in Korea I had to postpone.</p> <p>In the winter of 2023 in Korea, I made the decision to quit my job, allowing me ample time to train until the weather improved in March. It was during this time that I would finally metaphorically \"smash the champagne bottle\" on the frame of my bicycle and embark on my journey.</p> <p>In terms of equipment I bought a second hand bicycle and accessories for about a days wages, by my measurement I had the second worst bike of the 100+ people I passed by. For physical conditioning I would do a long ride every week, starting at 30, then 50 and 60km. This was interspersed with shorter rides of 10 and 20km. Five days before D-Day I stopped riding altogether to rest my legs.</p> <p>Most people ride the 4 rivers route in a group. I decided to travel alone, finding someone to match my pace would be difficult considering I didn't know my own pace for a multi-day trip. On the long rides I would listen to the audiobooks of \"Kitchen Confidential\" and \"Crying in H-Mart\", plugging in one airpod at a time and switching between left and right when each would run out of battery.</p> <p>For mentally preparing I subscribed to the information source www.koreabybike.com and watched hours and hours of youtube videos of people who had completed the trip. But most importantly I talked to my good friend Hans who had done the trip before. He gave me the advice that comes from hard fought experience: \"Buy seat cushioning, Keep an energy bar and a full water bottle in your pack and mostly try not to cry at I-Hwa-Ryeong hill\".</p>"},{"location":"blog/2023/05/28/bicycle-tour-halfway-across-the-country-seoul-daegu/#path","title":"Path","text":"<p>There is an ever present feeling of space along the Four Rivers bike path. There's a heuristic in urban design that a street can only be spacious if the width is bigger than the height of the surrounding buildings. If you start in the cramped megacity of Seoul you will feel the space opening up as highways are replaced by country roads and the skyscrapers are reduced to villas and then replaced by riverside mountains. In this part of the old country, the centuries old pagodas rise above the townships.</p> <p>Apart from the bends in the rivers, the path is almost a straight line from Seoul to Busan. The path is smooth with many conveniences, on the longest day I was able to cover over 100km with the nearest convenience store never further than 10km away. If you search on youtube there are some people that have chosen to walk the track, which is an amazing feat in itself. But this is not just a route of leisure. During the Korean war, displaced refugees formed a human caravan that would have started just North of Seoul and, following the river, ended in Busan.</p>"},{"location":"blog/2023/05/28/bicycle-tour-halfway-across-the-country-seoul-daegu/#day-1-seoul-to-yeoju","title":"Day 1 (Seoul to Yeoju)","text":"<p>For the first day I started on the Eastern edge of Seoul and rode 60 kilometres to the town of Yeoju. The train on a Saturday morning towards the Eastbound bike paths out of Seoul was filled with bicyclists and their equipment. By my estimate their were about 30 bicycles with a total value close to $100,000, fortunately I was there to bring down the average. Departing the train, carrying my bicycle down 2 flights of stairs, pushing off against a sea of bicycles, readjusting my gloves at the first set of traffic lights, chaos. Paldang station resembled a marathon starting line as soon as the gun goes off, pinballs left and right, 'sorry', 'excuse me', 'coming through'. Across the first bridge peace was restored as the number of riders, cafes convenience stores all dramatically reduced and then I felt that I was properly on my way.</p> <p>Halfway between Yeoju and Seoul, near the Ipo weir, I reached my first stamp collection booth. These booths resemble red telephone booths, with a single stamp attached by a rope to the inner compartment. Since I hadn't purchased a stamp passport, I improvised by stamping an old business card. As I exited the booth, I noticed two other riders had arrived. After they finished, I approached them and asked if they could take a photo of me with my bicycle in front of the booth. We started chatting about our destinations, we discovered that we lived just 10 minutes away from each other in Seoul.</p> <p></p> <p>As it was lunchtime and we were near a town known for its cold noodles, I suggested that we lunch together.</p> <p>\"My family is meeting us for lunch down the road, but I tell you what,\" said the older man, \"if we happen to cross paths again along the path, it will be fate. Let's make a plan to have a meal together then.\"</p> <p>So I rode three hundred metres down to the nearest cold noodle restaurant and waited in line, 10 minutes later the two men came by and we talked more. While I didn't consider this meeting to be a grand act of fate we decided to exchange numbers and talked of meeting in Seoul after the trip.</p> <p>Onwards to Yeoju, I passed by an abandoned airport runway which was overrun by campers with their ATV's and skateboards. I stopped at a cafe to recharge my legs, my phone and my mind. \"Ice latte please, is that a cookie? Thank you i'll have that as well\". Looking at the map to see where the next stampbooth was I noticed the cafe was within a 10 minute ride of the great King Sejong's final resting place. Originally buried in Seoul they moved his tomb to his hometown of Yeoju.</p> <p>On a personal level it was King Sejong's simplified writing system, Hangul, which attracted me to Korean language over others. By only a small stretch of logic you could say King Sejong himself brought me on this path. This connection felt more like a serendipitous encounter, a touch of fate, compared to the earlier meeting at the cold noodle restaurant. However, being mindful of conserving my energy for the journey ahead, I chose not to take the detour. Instead I booked my hotel for the night.</p> <p>The hotel was by the river, close to the old temple but most importantly none of the reviews mentioned cigarette smoke.I rode for three minutes from the hotel towards the Sinreuksa temple complex. The Sinreuksa pagoda lies on a cliff edge above the South Han River where it has inspired its visitors for nearly 700 years. I wasn't aware at the time but this temple stands alone as the only riverside temple in South Korea and yet there are hundreds of mountainside and seaside temples. Quality over quantity. </p> <p></p> <p></p>"},{"location":"blog/2023/05/28/bicycle-tour-halfway-across-the-country-seoul-daegu/#day-2-yeoju-to-suanbo","title":"Day 2 (Yeoju to Suanbo)","text":"<p>The alarm goes off at 7:30AM. My legs are aching less than expected. I checked out of the hotel at 8AM, 86km until I get to the old township of Suanbo, this will be the longest I've ever ridden.</p> <p>Nearing lunch time I pass by the Jungang-tap (literal translation: \"central tower\"), a 7 story pagoda on the outskirts of Chungju city. I sit in the shade in front of the tower. It's a Sunday but there are several troops of primary school aged children receiving history lectures from their caretakers. One of the children looks at me and whispers \"American\" to his friend. I'm not, but to deny it to aggresively has its own issues. </p> <p></p> <p>Another stamp and then I stop for a convenience store lunch. There's a group of 6 men and women with greying hairs outside enjoying a few beers. As for me, a microwave burger, kimbap and a can of coke is just about enough to fulfill my carbohydrate craving. As I exit the store one of the men asks me where I'm from. I tell them to guess. \"France?\" - no, \"America\" - definitely not. We go through continental Europe and Russia before I tell them the answer. The man explains that they made a wager, but they all lost. </p> <p>Another asks me where I'm headed, \"Initially Suanbo and then finally Daegu,\". They tell me about life in Chungju. They confirm my first estimate of it being a peaceful town, too peaceful for the younger generation moving to Seoul for jobs.</p> <p>\"Are you English teacher?\". This question reminds me that the only people around this city that look like me are English teachers, white collar work that attracts western talent is mostly in the global city of Seoul. I do my best to try and not sound like a stereotype when I tell her I used to work in finance but now I ride my bike. One of them tells me a popular myth that the tower in Chungju is the geographical center of South Korea, it would have to be incredible coincidence considering the border was only established 70 years ago but the tower has been around for 1300 years.</p> <p>\"Do you like Korea?\" one of the women in the group asks. I pause for a moment, appreciating the genuine curiosity and enthusiasm in her question. The first man extends a fried donut to me, which I gladly accept and devour.</p> <p>I strive to provide a unique answer each time I'm asked this question. Understanding the anticipation in the air, knowing that it's likely the first time for many in the group to interact with a foreigner, I delve into various aspects that I admire about Korea. I mention the well-developed public institutions, the efficient healthcare system, the rich cultural heritage and its global influence, the delicious and diverse cuisine, and, above all, the warmth and kindness of the people I have encountered during my journey. But at this moment what I like the most is the bikepaths and the fact I can leave my belongings unattended without concern.</p> <p>If I sit down too much longer I won't be able to get back up again. I thank them for allowing me to interrupt their afternoon, then I mount my bike while giving them the traditional farewell \"stay in peace\".</p> <p>I say adieu to the river, I'll see it again sometime tomorrow afternoon after I get through the mountain pass and the other side of I-Hwa-Ryeong hill.</p> <p>An hour before sundown I reach the township of Suanbo. Known for its hotsprings, the place has an abundance of hotels built during its heyday in the 1970s. The room I am in costs USD$40 a night. It's spacious enough that I can do all my laundry in the sink and dry my clothes on the heated wooden floor. Most importantly the hotspring water is pumped directly into the large hotel bath through a seperate pipe. Just what my quadriceps need.</p> <p></p> <p></p>"},{"location":"blog/2023/05/28/bicycle-tour-halfway-across-the-country-seoul-daegu/#day-3-suanbo-sangju-sangpoong-bridge","title":"Day 3 (Suanbo - Sangju Sangpoong Bridge)","text":"<p>7AM wake up. Some of the clothes are still damp, so I use the hairdryer to dry them off. I'm expecting I-Hwa-Ryeong to take an hour to walk up, so I set off early before breakfast. After an hour of riding I arrive at a cafe opposite the Korean Paper (hanji) Museum, I have a sandwich with a latte and emotionally prepare for the hike up the mountain.</p> <p>I-Hwa-Ryeong has an average elevation of 7 degrees but the gradient starts shallow and gets steeper. Between a 0 and 3 degree incline you might experience a phantom hill, where you only feel tired after riding for 10 or 20 minutes. At 3-6 degrees you will notice the hill but can maintain a riding pace for a indefinitely on the lowest gear, at 7 degrees and beyond you start to imagine what life would be like on an electric bike as you push the handlebars forward with a steady walk.</p> <p>In life most easy things can be done quickly and most difficult things take time, so we end up spending most of our time doing the hard things. This is particularly true when you drag a bicycle up a hill to ride it down on the other side. What took 1 hour and 4 kilometres to walk up took only 6 minutes to ride down. Wouldn't it be nice if the uphills took 6 minutes and the downhills took an hour.</p> <p>On the summit there is a gift shop/convenience store/restaurant. I order hand-cut noodles, dumplings and gatorade. Carbs and electrolytes. I stare into space for 20 minutes and start again.</p> <p>I have a 2 hour ride before I reach Jeomchon. As riders cross by on the otherside I try to wave and bow my head, rather than the legacy of the man who saved his bicycle from the rubbish heap I'd prefer \"the friendly foreigner who says hello\". During this part of the ride on country roads an older man rides beside me. He make a general gesture towards my bicycle, puts a thumbs up and says \"wow\". We talk and he compliments me on how far I have come. Later I would watch a youtube video consisting of short interviews asking riders how much their equipment cost, it wasn't rare for someones helmet to cost more than my bicycle, my clothes and my equipment combined.</p> <p>Thirty minutes before I reach my destination for the night, I stop at the Toe-gang Cathedral. This is the oldest Catholic church within the Sangju region. Early on, it was promoted to a parish, then demoted to a chapel-of-ease due to a lack of members. After combining with another church, it was promoted again. It's a beautiful building, but the congregation faces three threats. Firstly, younger people are migrating to major urban centers. Secondly, there is a declining influence of the Catholic Church in Korea. Finally, the declining population of Korea, due to a low birthrate, poses a challenge. Life is tough in the country, but I hope there will be many baptisms to come for the Toe-gang Church.</p> <p></p> <p>I arrived at the country hostel at 6 pm. The owner, a woman in her 60s, had a strong country accent, the type that's loud and fast, almost like she was permanently angry. After washing up, she told me to sit down for dinner. Her voice caught me off guard, so I said 'Sorry' and then 'Thank you'. In this area, the most noticeable landmark is the bike path from Seoul to Busan. Most people who arrive here are wearing lycra. I had dinner with one of the other guest riders who had departed from Daegu that morning. He advised me that the ride was flat, music to my ears. I went straight to bed afterward; the house was lights out by 9 pm.</p>"},{"location":"blog/2023/05/28/bicycle-tour-halfway-across-the-country-seoul-daegu/#day-4-sangju-sangpoong-bridge-daegu","title":"Day 4 (Sangju Sangpoong Bridge - Daegu)","text":"<p>The owner/housekeeper/head chef knocked on my door at 7 am; breakfast was ready. It consisted of hot miso soup with kimbap. I had eaten and packed before the other guest even got out of bed. The day was long, but the path ahead was even longer. I had 110 km between me and my final check-in in Daegu.</p> <p>I took off and immediately crossed the nearest bridge to the eastern side of the river. The western side of the river is home to an area called the 'Platform of the Gods,' renowned for its magnificent view over the Nakdong River. While I appreciate breathtaking views, recalling the story of Sisyphus, I decided to let the gods keep their platform to themselves. Nevertheless, the views on the western side were still splendid enough for weary-legged humans.</p> <p>My first stop is the Nakdong River Museum. Arriving on a Tuesday morning I am the only one there. They have a 4D movie theatre. I sample the 4D movie theatre which sprays me every time there is a water scene. I look through their rock garden. One of the information boards tells the story of the \"Nakdong river boatsman\" song. A music producer from Seoul was fleeing to Busan in 1953, he was ferried over by two sisters who were filling in for their older brother that had been conscripted. I fill up my water bottle with Nakdong water and ride on. </p> <p>I ride another 30 kilometres, although beautiful, I feel full from seeing the same Korean countryside views. My legs ache, the sweat has permeated my clothes but with the impetus of a task nearly done I ride on until I reach a cafe called \"The Story\" on the Northern edge of city of Gumi. Three stories tall, pressed against the river and they serve coffee and cookies this might be the true platform of the gods. One of the owners is painting caligraphy on A3 size canvas posters. Each sheet has large Chinese characters accompanied by small Korean phrases, the equivelant of \"Live, Laugh, Love\". I have no time for living, laughing or loving. I stare into space for 10 minutes and I'm on the road again. </p> <p>Lunch is at a convenience store with a view overlooking the Waegwan Railroad Bridge in Chilgok. This bridge holds a significant historical background as it was blown up by allied forces to impede the advance of the North Korean army.</p> <p>Another 15 kilometres and I arrive at Gasil cathedral. Built in 1895 by French missionaries it survived the Korean War by functioning as a hospital for both South and North Korean troops at different times. I stare into space as I sit at the cafe nearby, time is ticking and I know I must go. I have to go. But the body doesn't listen to what the mind has to say. The owner, a man in his 60's, see's me sitting alone and strikes up a conversation. He had a textile exporing business in the 80's which explains his impecabble English. He gives me a rundown of the local history, I ask questions, I tell him about my trip so far, I finish my coffee and now I really must go. I go. Two hours hard riding without stopping will get me to the edge of Daegu where I can ride by the city lights until I reach my accomodation.</p>"},{"location":"blog/2023/01/16/copulas/","title":"Copulas","text":"<p>Copulas are a way of estimating the multivariate distribution of independently modelled univariate distributions. They are a useful way of modelling the joint distribution of a set of random variables.</p> <p>Warning</p> <p>Gaussian copulas were used widely in risk modelling during the GFC, the joint probability estimates will only be as good as your marginal probability modelling and appropriateness of the copula.</p> <p>Going through an example might be useful. Imagine we have $1000 in AAPL stock and $1000 in MSFT stock. What is the chance that they both drop by 5% on the same day?</p> <p>We could approach this question using a multivariate bayesian approach, model a hidden factor that affects both the prices of MSFT and AAPL, estimate the most likely parameters, sample from the posterior and record the proportion of times that we see a greater than 5% drop in each of the share prices. That can be a lot of work especially if we have already independently modelled the underlying assets.</p>"},{"location":"blog/2023/01/16/copulas/#build-marginal-distributions-for-the-process-you-want-to-model","title":"Build marginal distributions for the process you want to model","text":"<p>First let's work out the distributions of each asset independently. We'll be using the normal distribution as that is conceptually the easiest to work through, although the copula approach works for any underlying distributions. Assuming the returns follow a normal distribution (not fat tailed enough, I know) then we will have to estimate the mean and standard deviation from the sample.</p> \\[   x \\sim \\mathcal{n}(\\mu,\\,\\sigma^{2})\\,. \\] Get the paramters for AAPL and MSFT returns distribution<pre><code>import yfinance as yf\ntickers = yf.Tickers('msft aapl')\ndf = tickers.history(period=\"5y\")\naapl_returns = df['Close']['AAPL'].pct_change().dropna()\nmsft_returns = df['Close']['MSFT'].pct_change().dropna()\nprint(\"AAPL return distribution\")\nprint(aapl_returns.describe())\n# AAPL return distribution\ncount    1258.000000\nmean        0.001252\nstd         0.020985\nmin        -0.128647\n25%        -0.008779\n50%         0.001140\n75%         0.012366\nmax         0.119808\nprint(\"MSFT return distribution\")\nprint(msft_returns.describe())\ncount    1258.000000\nmean        0.001149\nstd         0.019466\nmin        -0.147390\n25%        -0.007827\n50%         0.001289\n75%         0.010938\nmax         0.142169\n</code></pre> make CDF for AAPL and MSFT returns<pre><code>from scipy.stats import norm\ndef msft_return_probability(returns:float) -&gt; float:\n\"\"\"CDF of MSFT returns\n    &gt;&gt;&gt; round(msft_return_probability(-0.05),2)\n    0.01\n    \"\"\"\nmean = 0.00115\nstd = 0.01947\nzscore = (returns - mean)/std\nreturn norm.cdf(zscore)\ndef aapl_return_probability(returns:float) -&gt; float:\n\"\"\"CDF of AAPL returns\n    &gt;&gt;&gt; round(aapl_return_probability(-0.05),2)\n    0.03\n    \"\"\"\nmean = 0.001252\nstd = 0.020985\nzscore = (returns - mean)/std\nreturn norm.cdf(zscore)\n</code></pre>"},{"location":"blog/2023/01/16/copulas/#pick-a-copula-to-calculate-the-joint-distribution","title":"Pick a copula to calculate the joint distribution","text":"<p>We now have our underlying marginal distributions for each set of assets. Now we have to somehow combine them to form a joint distribution. The easiest way would be to assume that they are independent of each other. We could write an independent copula like this:</p> <pre><code>def independent_copula(u, v):\nreturn u * v\n</code></pre> <p>Using this copula the chance of them both going down at least 5% would be 0.01 * 0.03 or 3/10000. </p> <p>If they were perfectly correlated then the chance of them both going down at least 5% would be a much higher number, something like:</p> <pre><code>def correlated_copula(u,v):\nreturn max(u,v)\n</code></pre> <p>Note</p> <p>When we read this function for the inputs correlated_copula(0.8,0.3) we should say \"What is the chance of at least the 80th percentile of returns and at least the 30th percentile of returns?\" If they are completely correlated then when one distribution returns the 80th percentile then the other distribution must also return at least the 80th percentile. <pre><code>    correlated_copula(0.8,0.3) == correlated_copula(0.8,0.8) \n</code></pre></p> <p>Which gives us a much more realistic 3% chance, this is problematic in that we cannot prove that they are completely correlated and likely overestimates the risk. Going by this metric we could reduce our risk by dropping AAPL entirely and putting all our money in MSFT, this is the opposite of the mantra that \"Diversification is the only free lunch.\u201d</p> <p>Let's make the assumption that they are inversely correlated, which gives us the following copula:</p> <pre><code>def inversely_correlated_copula(u,v):\nreturn max(u+v-1,0)\n</code></pre> <p>Accordingly if AAPL were truly uncorrelated with MSFT then there would be no days in which they both lose money and the joint probability of a 5% loss on both assets would be 0.</p> <p>An alternative copula that we can use is the Gumbel copula which takes into account the correlation of the underlying marginal distributions. You can see the code below.</p> <pre><code>import numpy as np\ndef gumbel_copula(u, v, alpha):\nu = np.asarray(u)\nv = np.asarray(v)\n# compute copula\ncopula = np.exp(-(((-np.log(u))**alpha + (-np.log(v))**alpha))**(1/alpha))\nreturn copula\n</code></pre> <p>For the Gumbel copula, when alpha is equal to one then the copula behaves the same as the independent copula. When alpha approaches infinity it behaves like the inversely correlated copula. So you can guess that alpha is related to the correlation of the series u and v.</p> <p>To calculate alpha we first calculate the Kendall tau value of the two series. Kendall's tau can be described as a type of rank correlation coefficient. When making the calculation we use the probability values and not the values of the underlying returns i.e.</p> <pre><code>from scipy.stats import kendalltau\ndef calculate_alpha(u,v):\nu=np.array(u)\nv=np.array(v)\ntau = kendalltau(u,v).correlation\nreturn 1/(1-tau)\n</code></pre>"},{"location":"blog/2023/01/16/copulas/#apply-the-copula-to-find-the-joint-probability-of-two-events","title":"Apply the copula to find the joint probability of two events","text":"<p>Let's create the probability series from the returns series and calculate our alpha value for MSFT and AAPL:</p> calculate the joint probabilites for different copula<pre><code>alpha = calculate_alpha(aapl_returns.apply(lambda x: aapl_return_probability(x)),\nmsft_returns.apply(lambda x: msft_return_probability(x)))\nprint(alpha) \n#2.2015...  \nprint(aapl_return_probability(-0.05)*msft_return_probability(-0.05))\n# 0.0002..\nprint(gumbel_copula(aapl_return_probability(-0.05),msft_return_probability(-0.05))\n# 0.0032\n</code></pre> <p>Even with our poor modeling of the marginal distributions the Gumbel copula is able to give us a much better estimation of the probability that both companies would drop 5% in a single day. Looking at the history over the last 5 years there have been 7 out of 1258 trading days in which both companies dropped 5% (0.0056 by proportion).</p>"},{"location":"blog/2023/01/16/copulas/#graphing-the-result","title":"Graphing the result","text":"independent copula graphgumbel copula graph <p><pre><code>X,Y = np.mgrid[0:0.5:0.05, 0:0.5:0.05]\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X, Y, independent_copula(X,Y), c= 'red')\nplt.savefig(\"independent_copula.png\")\n</code></pre> </p> <p><pre><code>X,Y = np.mgrid[0:0.5:0.05, 0:0.5:0.05]\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X, Y, gumbel_copula(X,Y,alpha), c= 'red')\nplt.savefig(\"gumbel_copula.png\")\n</code></pre> </p> <p>The graph is steeper for the Gumbel copula, which means the joint probability is higher for two unlikely but correlated events.</p>"},{"location":"blog/2023/01/16/copulas/#wrap-up","title":"Wrap up","text":"<p>Copula's are used in risk management for their flexibility in combining a wide range of probability models into a joint probability. Even with a simple marginal probability model the combined copula was reasonably accurate in estimating the joint distribution for correlated assets. You could use copulas for predicting the network load on two related software services or for calculating the risk of correlated assets that are modelled differently.</p> <p>Below I have included a chart comparing the probability estimates for the Gumbel and Independent copulas for when <code>u=v</code>. Once again the Gumbel copula estimates a higher probability of two correlated but low probability events.</p>"},{"location":"blog/2023/01/16/geometric-distribution/","title":"Geometric Distribution","text":"<p>interview question</p> <p>If a job candidate has a 1% chance of passing an interview, what is the chance that he receives a job offer after 100 interviews?</p> <p>The first iteration I saw of this question required solving the problem without a calculator. The exact solution is easy with a bit of probability theory. The approximation requires a bit of intuition, and a much longer explanation.</p> <p>The probability that they succeed on the Nth interview is the probability of succeeding during an inteview after failing (n-1) interviews i.e.the pmf is</p> \\[ f(n) = p*(1-p)^{n-1} \\] <p>And the chance that they would have succeeded on at least 1 of the N interviews is the inverse of them failing every interview i.e. the cdf is</p> \\[ f(N \\le n) = 1 - (1-p)^n \\] <p>If we plug in our values for p=0.01 and n = 100 With a calculator the answer to two decimal places is 0.63.</p> <p>Given that p =1/n in the question my first thought was to find a general solution for all values where p is the inverse of n, i.e. p * n =1. Intuitively whether n is 100 or 1000 the answer should be approximately the same since the expected amount of interview successes is the same (p * n).</p> <p>The mathematical definition of e is close to what we want but we have the wrong sign in the brackets.</p> \\[ e = \\lim_{n \\to \\infty} (1+1/n)^n \\] <p>Let's introduce an approximation:</p> \\[ \\lim_{x \\to \\infty} (1 + 1/x)^n = (1 + n/x) \\] <p>Note</p> <p>in this approximation we can replace x with -x and n with -n and the approximation still holds i.e. for numbers close to 1 the power operation is similar to multiplication.</p> correect to the 5th decimal place<pre><code>assert abs(1.001**4) - 1.004 &lt; 0.00001\n</code></pre> <p>let's use this to get the negative version of the definition of e. Taking n to the limit of infinity:</p> \\[ (1-1/n)^n = (1+1/n)^{-n} = 1/e \\] <p>Each time we swap a sign we are taking the reciprocal. If we take the reciprocal twice we get the original (applying any inverse function twice is the identity function).</p> \\[ e = \\lim_{n \\to \\infty} (1-1/n)^{-n} \\] \\[ 1/e = \\lim_{n \\to \\infty} (1-1/n)^{n} \\] <p>with this second limit we are getting very close to the geometric distributions CDF, let's swap out the expression. for p * n =1</p> \\[ CDF = 1 - (1-p)^n = 1 - 1/e \\] e approximation vs calculator<pre><code>from math import e\ncalculated =  1 - (1-0.01)**100 #apprxomiately 0.63\nestimated = 1 - 1/e             #approximately 0.63\nassert abs(calculated - estimated)  &lt; 0.01\n</code></pre> <p>This approximation holds roughly to the number of decimal places of p.</p> <p>The expression is particularly nice when we assume n*p =1, but even without the assumption, we could still receive an answer in terms of e:</p> \\[ CDF = 1 - 1/(e^{p*n}) \\]"},{"location":"blog/2023/01/30/meritocracy/","title":"Meritocracy","text":"<p>I read Michael Sandel's book \"The Tyranny of Merit\" based on the recommendation of The Guardian's best books of 2020. The book is good and although it's focused on the American implementation of a meritocratic system it's enough to reveal the inconsistent values that I see in Australia and to an even worse extent in South Korea.</p> <p>I am a benefactor of the meritocratic systems of the countries that I have lived in. I've received an expensive education. I work in an economy where my talents and intellectual interests are highly valued, which gives me the double benefit of status and wealth. But I could have been born in a situation where I wasn't able to receive an expensive education or live in an economy where my labour is valued. And neither case would be the result of my choices.</p> <p>While reading I felt the most pity for the current generation of Koreans that are in or about to enter their 20s. South Korea, as Sandel noted, might be the most meritocratic country in the world. The university admission exams are conducted yearly, those that can't reach their favoured universities will repeat the exam 2 or 3 times. As such, exam first-timers are often competing against people that have dedicated 3 years to the exam which makes their prospects even worse.</p> <p>Even amongst those that graduate from the top universities, a large number will choose to sit the biannual public administration exam. Some of these exams have an admission rate less than Harvard which is why some people typically devote years to the task despite no guarantee of success.</p> <p>On the other end of the spectrum there are the 3D jobs (Dirty, Dangerous and Difficult). The unofficial fourth 'D' is 'demeaning'. 3D jobs aren't inherently low paid or 'demeaning'. But in a conformist society where the be-all and end-all is academic rigour then those that refuse to play are considered losers.</p> <p>Sandel spends a lot of time comparing the education system to a merit sorting machine. Sorting and ranking is ultimately a mathematical discipline. Take the feature vector [x1,x2...xn] and the weighting vector [w1,w2,...wn], calculate the inner product and now you have your single number for ranking. In this analogy the features would be a student's abilities and the weight vector would be how each ability is valued in society. If there are a variety of weighting vectors then each student has options of optimising their own feature vector. But if the weight vector is always [1,0,...0] then students must compete on the x1 feature.</p> <p>Even if there are other weight vectors around they have to be made known when students start optimising for their futures. What ends up being measured is a students' ability to optimise i.e. study for a test. There is a correlation between test marks and good characteristics such as intelligence and hard work. But there is an even higher correlation for parents income, which makes test scores as a measure of ability entirely unfair.</p> <p>I would recommend that you read this book and keep the idea of toxic meritocracy in your mind. If you want to move from the philosophical to the psychological I would recommend two more books. \"Laziness Does Not Exist\" by Devon Price which sets the scene for how terrible health outcomes when people buy in to meritocracy. And \"The Quick Fix\" by Jesse Singal which shows how large institutions have abdicated their responsibility of providing social welfare and reflected their responsibility on to the individual.</p>"},{"location":"blog/2022/12/20/python-profiling/","title":"Python Profiling","text":"<p>I've seen a few posts on Hacker News recently about writing fast and efficient code. Fortunately this example was written in Python which is probably the language that could save the most instruction cycles globally with a bit of optimization. I say this because Python is ubiquitous when it comes to writing prototype scripts that eventually get pushed to production under project deadlines.</p> <p>The rule of thumb that I like to use, and remind my coworkers, is that the order of code optimization is:</p> <ol> <li>Make it work - optimize for business functionality (MVP)</li> <li>Make it right - optimize for human readability (documentation, test cases, extendable)</li> <li>Make it fast - optimize for execution speed </li> </ol> <p>In the work of data science, the opportunities to get to the third stage are rare enough that they aren't covered in many learning materials but important enough that you need to know them. In this post i'll cover the profiling basics when using Python.</p> <p>Be aware that many profiling results are dependent on the current state of the computer running the profiler, it's best to run each result several times to normalize across background processes that may be happening.</p>"},{"location":"blog/2022/12/20/python-profiling/#timeit","title":"%timeit","text":"<p>For those using Jupyter notebooks or an iPython environment, %timeit is the easiest way to start measuring execution time of functions and therefore being able to compare speeds of different solutions.</p> timeit<pre><code>%timeit [i**3 for i in range(100)]\n#100000 loops, best of 5: 12.1 \u00b5s per loop\n</code></pre>"},{"location":"blog/2022/12/20/python-profiling/#memit","title":"%memit","text":"<p>memit is the easiest way to start memory profiling in a Jupyter Notebook or iPython environment. memit<pre><code>! pip install memory_profiler\n%load_ext memory_profiler\n%memit (i**3 for i in range(10000))\n%memit [i**3 for i in range(10000)]\n</code></pre></p>"},{"location":"blog/2022/12/20/python-profiling/#usrbintime","title":"/usr/bin/time","text":"<p>/usr/bin/time is a unix utility to time the execution of any program. It doesn't have as much detail as the python specific profilers but can be used for all types of programs that run as a unix CLI. <pre><code>/usr/bin/time curl https://matthewburke.xyz &gt;&gt; /dev/null </code></pre></p>"},{"location":"blog/2022/12/20/python-profiling/#cprofile","title":"cProfile","text":"<p>cProfile is part of the standard library and will show you the time spent in each function of a certain program. <pre><code>python -m cProfile -s cumulative script.py\npython -m cProfile -s cumulative script.py | grep script.py </code></pre></p>"},{"location":"blog/2022/12/20/python-profiling/#line_profiler","title":"line_profiler","text":"<p>Once you've worked out which function is using up the most CPU resources you can dive in deeper and investigate which line is using the most CPU resources with line_profiler. To run this you'll need to download the pip package line_profiler, add the @profile decorator to the functions you want to profile and finally run the line_profiler from the command line </p> function_to_profile.py<pre><code>@profile\ndef slow_add(a: int, b: int) -&gt; int:\ntime.sleep(1)\nreturn a+b\n</code></pre> <pre><code>kernprof -l function_to_profile.py\n</code></pre> <p>See the github repo github repo for more information.</p>"},{"location":"blog/2022/12/20/python-profiling/#memory_profiler","title":"memory_profiler","text":"<p>The memory_profiler works in much the same way as the line_profiler. Have a look at the official documentation to get started. </p>"},{"location":"blog/2022/12/20/python-profiling/#py-spy","title":"py-spy","text":"<p>py-spy (note the hyphen) is an incredible piece of work which allows you to profile a python process as it is running without slowing down the process (too much). You can imagine how useful it would be when trying to determine what the bottleneck is for a web server when serving real traffic. You can find more information on the github repo.</p>"},{"location":"projects/","title":"Projects","text":"<p>Short list of extra curricular projects that I have been a part of.</p>"},{"location":"projects/posts/wondrous/","title":"Wondrous.day","text":"<p>wondrous.day is a web application that I built along with my partner. The primary use case is for couples to create online wedding invitations to send to their guests by a URL.</p> <p>At its core is a CMS built with wagtail. As users add details they can see their edits in real time. Users can create their invitations for free and then go through a slack payment workflow when they are happy with the result.</p> <p>Running on a simple linode server. The backend logic is quite simple so I reasoned that the network traffic of images would be the bottleneck for system resources. That's why static and media assets are cached behind Clourdlares CDN while media assets are hosted in S3.</p>"},{"location":"blog/page/2/","title":"Blog","text":""}]}